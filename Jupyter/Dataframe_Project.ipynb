{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyspark session setup\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/hadoop/work/spark-3.2.0-bin-hadoop2.7\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.8\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3.8\"\n",
    "#!pip install -q findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/07 14:45:42 WARN util.Utils: Your hostname, hadoop-Lenovo-G50-80 resolves to a loopback address: 127.0.1.1; using 192.168.1.8 instead (on interface wlp3s0)\n",
      "21/12/07 14:45:42 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/07 14:45:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Dataframe Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- bonus: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "FileScan csv [employee_id#16,employee_name#17,department#18,state#19,salary#20,age#21,bonus#22] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/user/hadoop/OfficeDataProject.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<employee_id:int,employee_name:string,department:string,state:string,salary:int,age:int,bon...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(header = 'True',inferSchema ='True').csv(\"OfficeDataProject.csv\")\n",
    "df.printSchema()\n",
    "df.describe()\n",
    "df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|count(employee_id)|\n",
      "+------------------+\n",
      "|              1000|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print Total number of employee in the company \n",
    "df.agg(count(\"employee_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|count(department)|\n",
      "+-----------------+\n",
      "|                6|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print Total number of departments in the company \n",
    "df.agg(countDistinct(\"department\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|department|\n",
      "+----------+\n",
      "|     Sales|\n",
      "|Purchasing|\n",
      "| Marketing|\n",
      "|        HR|\n",
      "|   Finance|\n",
      "|  Accounts|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print departments names in the company \n",
    "df.select(col(\"department\")).distinct().orderBy(col(\"department\"),ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+\n",
      "|department|count(1)|Emp Salary|min(salary)|\n",
      "+----------+--------+----------+-----------+\n",
      "|     Sales|     169|    929430|       1103|\n",
      "|        HR|     171|    988537|       1013|\n",
      "|   Finance|     162|    835570|       1006|\n",
      "|Purchasing|     166|    852551|       1105|\n",
      "| Marketing|     170|    881983|       1031|\n",
      "|  Accounts|     162|    841873|       1007|\n",
      "+----------+--------+----------+-----------+\n",
      "\n",
      "+----------+-----+--------+\n",
      "|department|state|count(1)|\n",
      "+----------+-----+--------+\n",
      "|  Accounts|   NY|      34|\n",
      "|  Accounts|   CA|      35|\n",
      "|  Accounts|   WA|      27|\n",
      "|  Accounts|   AK|      37|\n",
      "|  Accounts|   LA|      29|\n",
      "|   Finance|   LA|      29|\n",
      "|   Finance|   CA|      35|\n",
      "|   Finance|   NY|      31|\n",
      "|   Finance|   WA|      30|\n",
      "|   Finance|   AK|      37|\n",
      "|        HR|   LA|      41|\n",
      "|        HR|   NY|      30|\n",
      "|        HR|   CA|      28|\n",
      "|        HR|   AK|      25|\n",
      "|        HR|   WA|      47|\n",
      "| Marketing|   AK|      42|\n",
      "| Marketing|   NY|      30|\n",
      "| Marketing|   WA|      39|\n",
      "| Marketing|   CA|      33|\n",
      "| Marketing|   LA|      26|\n",
      "+----------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print total Number of emplooyees in each department \n",
    "df.groupBy(col(\"department\")).agg(count(\"*\"),sum(\"salary\").alias(\"Emp Salary\"),min(\"salary\")).show()\n",
    "# Print total Number of emplooyees in each state in each department\n",
    "df.groupBy(col(\"department\"),col(\"state\")).agg(count(\"*\")).orderBy(\"department\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|department|min_salary|max_salary|\n",
      "+----------+----------+----------+\n",
      "|   Finance|      1006|      9899|\n",
      "|  Accounts|      1007|      9890|\n",
      "|        HR|      1013|      9982|\n",
      "| Marketing|      1031|      9974|\n",
      "|     Sales|      1103|      9982|\n",
      "|Purchasing|      1105|      9985|\n",
      "+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print min and max salary in each department and sort salary in assending order\n",
    "df.groupBy(col(\"department\")).agg(min(\"salary\").alias(\"min_salary\"),max(\"salary\").alias(\"max_salary\")) \\\n",
    ".orderBy(col(\"min_salary\").asc(),col(\"min_salary\").asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       employee_name|\n",
      "+--------------------+\n",
      "|     Melissia Dedman|\n",
      "|       Megan Gallman|\n",
      "|     Trena Clemencia|\n",
      "|        Tyree Soules|\n",
      "|       Suzanne Trena|\n",
      "|         Herder Nitz|\n",
      "|     Exie Georgeanna|\n",
      "|     Antonio Ruzicka|\n",
      "|        Clune Norene|\n",
      "|       Janine Mayeda|\n",
      "|      Herder Gallman|\n",
      "|     Casimira Katlyn|\n",
      "|   Tenenbaum Suzanne|\n",
      "|       Grigg Debroah|\n",
      "|          Nena Rocha|\n",
      "|    Clemencia Locust|\n",
      "|       Leif Lemaster|\n",
      "|   Clemencia Rudolph|\n",
      "|         Janey Amber|\n",
      "|Ellingsworth Meli...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print names of employees working in NY state under Finance department whose bouns are greater than the average  \n",
    "# bonuses of employees in NY\n",
    "avg_bonus =df.filter(col(\"state\") == 'NY').groupBy(col(\"state\")).agg(avg(\"bonus\").alias(\"avg_bonus\")) \\\n",
    "            .select(\"avg_bonus\").collect()[0]['avg_bonus'] \n",
    "df.select(col(\"employee_name\")).filter((col(\"salary\") >= avg_bonus) & (col(\"department\") == 'Finance')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+----------+-----+------+---+-----+\n",
      "|employee_id|      employee_name|department|state|salary|age|bonus|\n",
      "+-----------+-------------------+----------+-----+------+---+-----+\n",
      "|       1000|          Nitz Leif| Marketing|   CA|  6631| 26|  543|\n",
      "|       1001|    Melissia Dedman|   Finance|   AK|  4527| 43| 1290|\n",
      "|       1002|  Rudolph Barringer|        HR|   LA|  3622| 43| 1445|\n",
      "|       1003|        Tamra Amber|  Accounts|   AK|  6217| 47| 1291|\n",
      "|       1004|        Mullan Nitz|Purchasing|   CA|  6185| 34| 1394|\n",
      "|       1005|      Zollner Karie|  Accounts|   CA|  3343| 27| 1078|\n",
      "|       1006|Kaczorowski Zollner|     Sales|   CA|  7701| 21| 1834|\n",
      "|       1007|      Nakano Locust| Marketing|   LA|  3944| 23| 1823|\n",
      "|       1008|  Recalde Kensinger|  Accounts|   LA|  4204| 48| 1330|\n",
      "|       1009|        Imai Hallie|  Accounts|   AK|  5561| 38| 1557|\n",
      "|       1010|    Debroah Gallman|  Accounts|   NY|  9808| 35|  817|\n",
      "|       1011|   Barringer Escoto|Purchasing|   WA|  2185| 49| 1706|\n",
      "|       1012|      Soules Coogan|  Accounts|   AK|  8830| 43| 1914|\n",
      "|       1013|      Luisa Suzanne|  Accounts|   CA|  1651| 37| 1095|\n",
      "|       1014|      Marvis Cobian|Purchasing|   NY|  5561| 41| 1765|\n",
      "|       1015|   Cobian Kensinger|     Sales|   LA|  2483| 21|  632|\n",
      "|       1016|      Gilma Margret| Marketing|   CA|  3419| 45| 1762|\n",
      "|       1017| Ellingsworth Ilana|  Accounts|   WA| 10114| 26| 1964|\n",
      "|       1018| Vankirk Jacquelyne|Purchasing|   NY|  9136| 47| 1192|\n",
      "|       1019|    Zollner Juliana|        HR|   NY| 10239| 30| 1119|\n",
      "+-----------+-------------------+----------+-----+------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# raise salary $500 of all th emeployees whose age is greater than 45\n",
    "df.withColumn(\"salary\",lit(500) + col(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+----------+-----+------+---+-----+------------------+\n",
      "|employee_id|      employee_name|department|state|salary|age|bonus|Incremented salary|\n",
      "+-----------+-------------------+----------+-----+------+---+-----+------------------+\n",
      "|       1000|          Nitz Leif| Marketing|   CA|  6131| 26|  543|              6131|\n",
      "|       1001|    Melissia Dedman|   Finance|   AK|  4027| 43| 1290|              4027|\n",
      "|       1002|  Rudolph Barringer|        HR|   LA|  3122| 43| 1445|              3122|\n",
      "|       1003|        Tamra Amber|  Accounts|   AK|  5717| 47| 1291|              6217|\n",
      "|       1004|        Mullan Nitz|Purchasing|   CA|  5685| 34| 1394|              5685|\n",
      "|       1005|      Zollner Karie|  Accounts|   CA|  2843| 27| 1078|              2843|\n",
      "|       1006|Kaczorowski Zollner|     Sales|   CA|  7201| 21| 1834|              7201|\n",
      "|       1007|      Nakano Locust| Marketing|   LA|  3444| 23| 1823|              3444|\n",
      "|       1008|  Recalde Kensinger|  Accounts|   LA|  3704| 48| 1330|              4204|\n",
      "|       1009|        Imai Hallie|  Accounts|   AK|  5061| 38| 1557|              5061|\n",
      "|       1010|    Debroah Gallman|  Accounts|   NY|  9308| 35|  817|              9308|\n",
      "|       1011|   Barringer Escoto|Purchasing|   WA|  1685| 49| 1706|              2185|\n",
      "|       1012|      Soules Coogan|  Accounts|   AK|  8330| 43| 1914|              8330|\n",
      "|       1013|      Luisa Suzanne|  Accounts|   CA|  1151| 37| 1095|              1151|\n",
      "|       1014|      Marvis Cobian|Purchasing|   NY|  5061| 41| 1765|              5061|\n",
      "|       1015|   Cobian Kensinger|     Sales|   LA|  1983| 21|  632|              1983|\n",
      "|       1016|      Gilma Margret| Marketing|   CA|  2919| 45| 1762|              3419|\n",
      "|       1017| Ellingsworth Ilana|  Accounts|   WA|  9614| 26| 1964|              9614|\n",
      "|       1018| Vankirk Jacquelyne|Purchasing|   NY|  8636| 47| 1192|              9136|\n",
      "|       1019|    Zollner Juliana|        HR|   NY|  9739| 30| 1119|              9739|\n",
      "+-----------+-------------------+----------+-----+------+---+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#using udf raise salary $500 of all th emeployees whose age is greater than 45 \n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def salary_incr(cur_salary,age):\n",
    "    if age >= 45:\n",
    "        salary_incr = cur_salary + 500\n",
    "    else:\n",
    "        salary_incr = cur_salary\n",
    "        \n",
    "    return salary_incr\n",
    "\n",
    "SalaryIncrUDF = udf (lambda x,y : salary_incr(x,y),IntegerType())\n",
    "\n",
    "df.withColumn(\"Incremented salary\",SalaryIncrUDF(col(\"salary\"),col(\"age\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtite file modes\n",
    "#overwrite\n",
    "#append\n",
    "#error\n",
    "#ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/07 15:23:32 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-830212574-127.0.1.1-1633618224355:blk_1073742467_1652\n",
      "java.net.SocketTimeoutException: 65000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:56754 remote=/127.0.0.1:50010]\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)\n",
      "\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n",
      "\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2292)\n",
      "\tat org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:847)\n"
     ]
    }
   ],
   "source": [
    "# create DF of all the employees whose age is greater than 45 an save them to file\n",
    "df.write.mode(\"overwrite\").options(header = 'True').csv('output/StudData.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
